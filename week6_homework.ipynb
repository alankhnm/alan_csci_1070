{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e250907e-3d0f-4280-bf00-0ca302f2a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import List\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "38ec6738-5f1d-4f08-850f-4b7d3b87b01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ind_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>Car_Owner</th>\n",
       "      <th>Propert_Owner</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>Type_Income</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Housing_type</th>\n",
       "      <th>Birthday_count</th>\n",
       "      <th>Employed_days</th>\n",
       "      <th>Mobile_phone</th>\n",
       "      <th>Work_Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>EMAIL_ID</th>\n",
       "      <th>Type_Occupation</th>\n",
       "      <th>Family_Members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008827</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-18772.0</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5009744</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5009746</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5009749</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5009752</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ind_ID GENDER Car_Owner Propert_Owner  CHILDREN  Annual_income  \\\n",
       "0  5008827      M         Y             Y         0       180000.0   \n",
       "1  5009744      F         Y             N         0       315000.0   \n",
       "2  5009746      F         Y             N         0       315000.0   \n",
       "3  5009749      F         Y             N         0            NaN   \n",
       "4  5009752      F         Y             N         0       315000.0   \n",
       "\n",
       "            Type_Income         EDUCATION Marital_status       Housing_type  \\\n",
       "0             Pensioner  Higher education        Married  House / apartment   \n",
       "1  Commercial associate  Higher education        Married  House / apartment   \n",
       "2  Commercial associate  Higher education        Married  House / apartment   \n",
       "3  Commercial associate  Higher education        Married  House / apartment   \n",
       "4  Commercial associate  Higher education        Married  House / apartment   \n",
       "\n",
       "   Birthday_count  Employed_days  Mobile_phone  Work_Phone  Phone  EMAIL_ID  \\\n",
       "0        -18772.0         365243             1           0      0         0   \n",
       "1        -13557.0           -586             1           1      1         0   \n",
       "2             NaN           -586             1           1      1         0   \n",
       "3        -13557.0           -586             1           1      1         0   \n",
       "4        -13557.0           -586             1           1      1         0   \n",
       "\n",
       "  Type_Occupation  Family_Members  \n",
       "0             NaN               2  \n",
       "1             NaN               2  \n",
       "2             NaN               2  \n",
       "3             NaN               2  \n",
       "4             NaN               2  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Credit_Card.csv')\n",
    "label_df = pd.read_csv('Credit_card_label.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d709d16a-c2f5-4f81-ae4f-ec1bfd35cde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ind_ID', 'GENDER', 'Car_Owner', 'Propert_Owner', 'CHILDREN',\n",
       "       'Annual_income', 'Type_Income', 'EDUCATION', 'Marital_status',\n",
       "       'Housing_type', 'Birthday_count', 'Employed_days', 'Mobile_phone',\n",
       "       'Work_Phone', 'Phone', 'EMAIL_ID', 'Type_Occupation', 'Family_Members'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ecde7c91-b64c-4bcf-ba37-f948908d38a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ind_ID               int64\n",
       "GENDER              object\n",
       "Car_Owner           object\n",
       "Propert_Owner       object\n",
       "CHILDREN             int64\n",
       "Annual_income      float64\n",
       "Type_Income         object\n",
       "EDUCATION           object\n",
       "Marital_status      object\n",
       "Housing_type        object\n",
       "Birthday_count     float64\n",
       "Employed_days        int64\n",
       "Mobile_phone         int64\n",
       "Work_Phone           int64\n",
       "Phone                int64\n",
       "EMAIL_ID             int64\n",
       "Type_Occupation     object\n",
       "Family_Members       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8afd2b0e-6899-4a8d-9a5c-f439c7e88fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, label_df, on='Ind_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e871c28a-fe72-4ab7-a28d-dc74067cdb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ind_ID               int64\n",
       "GENDER              object\n",
       "Car_Owner           object\n",
       "Propert_Owner       object\n",
       "CHILDREN             int64\n",
       "Annual_income      float64\n",
       "Type_Income         object\n",
       "EDUCATION           object\n",
       "Marital_status      object\n",
       "Housing_type        object\n",
       "Birthday_count     float64\n",
       "Employed_days        int64\n",
       "Mobile_phone         int64\n",
       "Work_Phone           int64\n",
       "Phone                int64\n",
       "EMAIL_ID             int64\n",
       "Type_Occupation     object\n",
       "Family_Members       int64\n",
       "label                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2abbef-2428-4809-8984-01e6e48a5794",
   "metadata": {},
   "source": [
    "# **1. (5 pts) Clean your dataset to turn categorical values into numerical ones. One-hot encoding is likely the answer, but it depends on the dataset. Your data may have ordinal columns, for example where one-hot encoding is not as appropriate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43930179-b9ee-4c54-bafa-214894ee7da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ind_ID</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>Birthday_count</th>\n",
       "      <th>Employed_days</th>\n",
       "      <th>Mobile_phone</th>\n",
       "      <th>Work_Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>EMAIL_ID</th>\n",
       "      <th>Family_Members</th>\n",
       "      <th>...</th>\n",
       "      <th>Type_Occupation_Laborers</th>\n",
       "      <th>Type_Occupation_Low-skill Laborers</th>\n",
       "      <th>Type_Occupation_Managers</th>\n",
       "      <th>Type_Occupation_Medicine staff</th>\n",
       "      <th>Type_Occupation_Private service staff</th>\n",
       "      <th>Type_Occupation_Realty agents</th>\n",
       "      <th>Type_Occupation_Sales staff</th>\n",
       "      <th>Type_Occupation_Secretaries</th>\n",
       "      <th>Type_Occupation_Security staff</th>\n",
       "      <th>Type_Occupation_Waiters/barmen staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5010864</td>\n",
       "      <td>1</td>\n",
       "      <td>450000</td>\n",
       "      <td>-18173</td>\n",
       "      <td>-678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5010868</td>\n",
       "      <td>1</td>\n",
       "      <td>450000</td>\n",
       "      <td>-18173</td>\n",
       "      <td>-678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5010869</td>\n",
       "      <td>1</td>\n",
       "      <td>450000</td>\n",
       "      <td>-18173</td>\n",
       "      <td>-678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5018498</td>\n",
       "      <td>0</td>\n",
       "      <td>90000</td>\n",
       "      <td>-18950</td>\n",
       "      <td>-1002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5018501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18950</td>\n",
       "      <td>-1002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>5118268</td>\n",
       "      <td>1</td>\n",
       "      <td>360000</td>\n",
       "      <td>-11294</td>\n",
       "      <td>-3536</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>5028645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11957</td>\n",
       "      <td>-2182</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>5023655</td>\n",
       "      <td>0</td>\n",
       "      <td>225000</td>\n",
       "      <td>-10229</td>\n",
       "      <td>-1209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>5115992</td>\n",
       "      <td>2</td>\n",
       "      <td>180000</td>\n",
       "      <td>-13174</td>\n",
       "      <td>-2477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>5118219</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>-15292</td>\n",
       "      <td>-645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1060 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ind_ID  CHILDREN  Annual_income  Birthday_count  Employed_days  \\\n",
       "8     5010864         1         450000          -18173           -678   \n",
       "9     5010868         1         450000          -18173           -678   \n",
       "10    5010869         1         450000          -18173           -678   \n",
       "11    5018498         0          90000          -18950          -1002   \n",
       "12    5018501         0              0          -18950          -1002   \n",
       "...       ...       ...            ...             ...            ...   \n",
       "1542  5118268         1         360000          -11294          -3536   \n",
       "1543  5028645         0              0          -11957          -2182   \n",
       "1544  5023655         0         225000          -10229          -1209   \n",
       "1545  5115992         2         180000          -13174          -2477   \n",
       "1546  5118219         0         270000          -15292           -645   \n",
       "\n",
       "      Mobile_phone  Work_Phone  Phone  EMAIL_ID  Family_Members  ...  \\\n",
       "8                1           0      1         1               3  ...   \n",
       "9                1           0      1         1               3  ...   \n",
       "10               1           0      1         1               1  ...   \n",
       "11               1           1      1         0               2  ...   \n",
       "12               1           1      1         0               2  ...   \n",
       "...            ...         ...    ...       ...             ...  ...   \n",
       "1542             1           0      1         0               3  ...   \n",
       "1543             1           0      0         0               2  ...   \n",
       "1544             1           0      0         0               1  ...   \n",
       "1545             1           0      0         0               4  ...   \n",
       "1546             1           1      1         0               2  ...   \n",
       "\n",
       "      Type_Occupation_Laborers  Type_Occupation_Low-skill Laborers  \\\n",
       "8                            0                                   0   \n",
       "9                            0                                   0   \n",
       "10                           0                                   0   \n",
       "11                           0                                   0   \n",
       "12                           0                                   0   \n",
       "...                        ...                                 ...   \n",
       "1542                         0                                   0   \n",
       "1543                         0                                   0   \n",
       "1544                         0                                   0   \n",
       "1545                         0                                   0   \n",
       "1546                         0                                   0   \n",
       "\n",
       "      Type_Occupation_Managers  Type_Occupation_Medicine staff  \\\n",
       "8                            0                               0   \n",
       "9                            0                               0   \n",
       "10                           0                               0   \n",
       "11                           0                               0   \n",
       "12                           0                               0   \n",
       "...                        ...                             ...   \n",
       "1542                         0                               0   \n",
       "1543                         1                               0   \n",
       "1544                         0                               0   \n",
       "1545                         1                               0   \n",
       "1546                         0                               0   \n",
       "\n",
       "      Type_Occupation_Private service staff  Type_Occupation_Realty agents  \\\n",
       "8                                         0                              0   \n",
       "9                                         0                              0   \n",
       "10                                        0                              0   \n",
       "11                                        0                              0   \n",
       "12                                        0                              0   \n",
       "...                                     ...                            ...   \n",
       "1542                                      0                              0   \n",
       "1543                                      0                              0   \n",
       "1544                                      0                              0   \n",
       "1545                                      0                              0   \n",
       "1546                                      0                              0   \n",
       "\n",
       "      Type_Occupation_Sales staff  Type_Occupation_Secretaries  \\\n",
       "8                               0                            0   \n",
       "9                               0                            0   \n",
       "10                              0                            0   \n",
       "11                              0                            0   \n",
       "12                              0                            0   \n",
       "...                           ...                          ...   \n",
       "1542                            0                            0   \n",
       "1543                            0                            0   \n",
       "1544                            0                            0   \n",
       "1545                            0                            0   \n",
       "1546                            0                            0   \n",
       "\n",
       "      Type_Occupation_Security staff  Type_Occupation_Waiters/barmen staff  \n",
       "8                                  0                                     0  \n",
       "9                                  0                                     0  \n",
       "10                                 0                                     0  \n",
       "11                                 0                                     0  \n",
       "12                                 0                                     0  \n",
       "...                              ...                                   ...  \n",
       "1542                               0                                     0  \n",
       "1543                               0                                     0  \n",
       "1544                               0                                     0  \n",
       "1545                               0                                     0  \n",
       "1546                               0                                     0  \n",
       "\n",
       "[1060 rows x 46 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_and_encode_data(merged_df: pd.DataFrame, \n",
    "                          numerical_cols: List[str] = ['Annual_income', 'Birthday_count'], \n",
    "                          categorical_cols: List[str] = ['GENDER', 'Car_Owner', 'Propert_Owner', 'Type_Income', \n",
    "                                                         'EDUCATION', 'Marital_status', 'Housing_type', 'Type_Occupation'], \n",
    "                          occupation_col: str = 'Type_Occupation') -> pd.DataFrame:\n",
    "    for col in numerical_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    merged_df.dropna(subset=[occupation_col], inplace=True)\n",
    "    \n",
    "    merged_df['GENDER'] = merged_df['GENDER'].fillna(merged_df['GENDER'].mode()[0])\n",
    "    \n",
    "    df_encoded = pd.get_dummies(merged_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    df_encoded = df_encoded.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    df_encoded = df_encoded.astype(int)\n",
    "    \n",
    "    return df_encoded\n",
    "df_encoded = clean_and_encode_data(merged_df)\n",
    "df_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c4ca0-3e3a-4eae-a066-967d160ae6ac",
   "metadata": {},
   "source": [
    "# **2. (3 pts) Perform univariate linear regression on the dataset. Select your variable to predict. How well did this model perform? Is this a good approach for this dataset? Why or why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f5437ab3-7788-43c1-9f5c-9a3015a70bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.11819873066694385, R2: -0.010801559404991723\n"
     ]
    }
   ],
   "source": [
    "def credit_card_approval_model(df_encoded: pd.DataFrame, \n",
    "                               feature_cols: List[str], \n",
    "                               target_col: str) -> float:\n",
    "\n",
    "    merged_df = pd.merge(df, label_df, on='Ind_ID')\n",
    "\n",
    "    X = df_encoded[feature_cols]\n",
    "    y = df_encoded[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mse, r2\n",
    "\n",
    "feature_cols = ['Annual_income']\n",
    "target_col = 'label'\n",
    "\n",
    "mse, r2 = credit_card_approval_model(df_encoded, feature_cols, target_col)\n",
    "print(f'MSE: {mse}, R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb86280e-ea92-42da-83c3-6fc719c79f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cab806-ad7f-4f26-ae2a-603571c13ab4",
   "metadata": {},
   "source": [
    "My model is not explaining any meaningful variance in the data and is actually performing worse than predicting the mean of the target variable due to the r squared value being less than 0. However my MSE is realatively low which mean it does good job predicting close to actual target values. Overall this model is bad espcially since linear regression is better suited for continous output and not a classification task where output is binary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d40fe-5b4b-4696-9999-10cd65262a9c",
   "metadata": {},
   "source": [
    "# **3. (8 pts) Perform KNN on this dataset. As part of this, write a function that selects the optimal value of k. How well did this model perform?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f1d95dc9-5c4a-448d-9c54-33dc67d856e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k: 1\n",
      "Test Accuracy: 0.8490566037735849\n",
      "Confusion Matrix:\n",
      "[[168  13]\n",
      " [ 19  12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       181\n",
      "           1       0.48      0.39      0.43        31\n",
      "\n",
      "    accuracy                           0.85       212\n",
      "   macro avg       0.69      0.66      0.67       212\n",
      "weighted avg       0.84      0.85      0.84       212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_k(df_encoded: pd.DataFrame, \n",
    "                   target_col: str, \n",
    "                   k_range: Tuple[int, int] = (1, 21), \n",
    "                   test_size: float = 0.2, \n",
    "                   random_state: int = 42) -> float:\n",
    "\n",
    "    X = df_encoded.drop(columns=[target_col])\n",
    "    y = df_encoded[target_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    best_k = 0\n",
    "    best_score = 0\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=((2*k)+1))\n",
    "        knn.fit(X_train, y_train)\n",
    "        score = knn.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_score = score\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return best_k, test_accuracy, conf_matrix, class_report\n",
    "\n",
    "best_k, test_accuracy, conf_matrix, class_report = find_optimal_k(df_encoded, target_col='label')\n",
    "\n",
    "print(f\"Optimal k: {best_k}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe3389-af80-49d1-ba9b-b9a4358a9f26",
   "metadata": {},
   "source": [
    "The overall accuracy is relatively high, but accuracy alone doesn't fully reflect the model's ability to handle class imbalances.\n",
    "The model predicts Class 0 well (168 correct), but struggles with Class 1, misclassifying 19 out of 31 instances.\n",
    "\n",
    "**Class 0 (Negative Class)**\n",
    "Precision: 90% of predicted Class 0 are correct.\n",
    "Recall: 93% of actual Class 0 are correctly identified.\n",
    "\n",
    "**Class 1 (Positive Class)**\n",
    "Precision: Only 48% of predicted Class 1 are correct.\n",
    "Recall: The model captures only 39% of actual Class 1 instances.\n",
    "\n",
    "**F1-score**\n",
    "Class 0: Strong balance between precision and recall.\n",
    "Class 1: Weak performance in predicting Class 1.\n",
    "\n",
    "**Macro avg F1-score: 0.67**\n",
    "Reflects poor performance for the minority class (Class 1).\n",
    "\n",
    "**Weighted avg F1-score: 0.84**\n",
    "Driven by the high accuracy of the dominant class (Class 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4617e-a811-4801-9e6f-996cf0f756af",
   "metadata": {},
   "source": [
    "# **4. (6 pts) Work with your dataset to perform logistic regression. How well did this perform?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78613ede-4896-4127-991f-c2f702746c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6037735849056604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       121\n",
      "           1       0.57      0.30      0.39        91\n",
      "\n",
      "    accuracy                           0.60       212\n",
      "   macro avg       0.59      0.57      0.55       212\n",
      "weighted avg       0.60      0.60      0.57       212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_logistic_regression(df_encoded: pd.DataFrame) -> float:\n",
    "    X = df_encoded.drop(columns=['label', 'Ind_ID'])\n",
    "    y = df_encoded['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, report\n",
    "print(accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0c701-4e2a-4d24-a5cc-d2966891754c",
   "metadata": {},
   "source": [
    "The overall accuracy of 60.4% indicates a moderate performance.\n",
    "\n",
    "**Class 0 (Negative Class)**\n",
    "Precision: 61% of the predictions for Class 0 are correct.\n",
    "Recall:The model correctly identifies 83% of the actual Class 0 instances.\n",
    "F1-score:A balanced score for precision and recall in Class 0, showing decent performance.\n",
    "\n",
    "**Class 1 (Positive Class)**\n",
    "Precision: 57% of the predictions for Class 1 are correct.\n",
    "Recall:  The model only captures 30% of the actual Class 1 instances, indicating poor performance in identifying the minority class.\n",
    "F1-score: Low, indicating that the model struggles significantly with the minority class.\n",
    "\n",
    "**Averages:**\n",
    "Macro Average F1-score: 0.55\n",
    "Reflects an overall weak performance across both classes, particularly due to poor Class 1 recall.\n",
    "Weighted Average F1-score: 0.57\n",
    "Similar to the accuracy score, showing that performance is driven by the dominant class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bb95a-77df-4ca7-8f73-5749d6736a36",
   "metadata": {},
   "source": [
    "# **5. (3 pts) Perform normalization on your dataset. Does it change the performance for 2-4? What is the best measure of performance for your dataset (accuracy or something else) and why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dbb3771c-e8bf-4645-b707-25e784a02497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.11819873066694385, R2: -0.010801559404991723\n"
     ]
    }
   ],
   "source": [
    "#Normalized question 2\n",
    "def credit_card_approval_model(df_encoded: pd.DataFrame, \n",
    "                               feature_cols: List[str], \n",
    "                               target_col: str) -> float:\n",
    "\n",
    "    merged_df = pd.merge(df, label_df, on='Ind_ID')\n",
    "\n",
    "    X = df_encoded[feature_cols]\n",
    "    y = df_encoded[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train_sc, y_train)\n",
    "\n",
    "    y_pred = lin_reg.predict(X_test_sc)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mse, r2\n",
    "\n",
    "feature_cols = ['Annual_income']\n",
    "target_col = 'label'\n",
    "\n",
    "mse, r2 = credit_card_approval_model(df_encoded, feature_cols, target_col)\n",
    "print(f'MSE: {mse}, R2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3ac0f-d860-44ec-bb12-770f42501b07",
   "metadata": {},
   "source": [
    "For question 2 normalizing the dataset didn't change the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "30bb24ce-600e-4b89-93f4-e9c2b507e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k: 1\n",
      "Test Accuracy: 0.8632075471698113\n",
      "Confusion Matrix:\n",
      "[[171  10]\n",
      " [ 19  12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       181\n",
      "           1       0.55      0.39      0.45        31\n",
      "\n",
      "    accuracy                           0.86       212\n",
      "   macro avg       0.72      0.67      0.69       212\n",
      "weighted avg       0.85      0.86      0.85       212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Normalized question 3\n",
    "def find_optimal_k(df_encoded: pd.DataFrame, \n",
    "                   target_col: str, \n",
    "                   k_range: Tuple[int, int] = (1, 21), \n",
    "                   test_size: float = 0.2, \n",
    "                   random_state: int = 42) -> float:\n",
    "\n",
    "    X = df_encoded.drop(columns=[target_col])\n",
    "    y = df_encoded[target_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "    best_k = 0\n",
    "    best_score = 0\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=((2*k)+1))\n",
    "        knn.fit(X_train_sc, y_train)\n",
    "        score = knn.score(X_test_sc, y_test)\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_score = score\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn.fit(X_train_sc, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_test_sc)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return best_k, test_accuracy, conf_matrix, class_report\n",
    "\n",
    "best_k, test_accuracy, conf_matrix, class_report = find_optimal_k(df_encoded, target_col='label')\n",
    "\n",
    "print(f\"Optimal k: {best_k}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d4693-b6d3-4f44-af00-d6815f81f4b5",
   "metadata": {},
   "source": [
    "For question 3 most of the testers displayed better performance such as improved accuracy, more precision and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9299e405-c788-4025-a52f-660fb1775b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6037735849056604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       121\n",
      "           1       0.57      0.30      0.39        91\n",
      "\n",
      "    accuracy                           0.60       212\n",
      "   macro avg       0.59      0.57      0.55       212\n",
      "weighted avg       0.60      0.60      0.57       212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Normalized question 4\n",
    "def train_logistic_regression(df_encoded: pd.DataFrame) -> float:\n",
    "    X = df_encoded.drop(columns=['label', 'Ind_ID'])\n",
    "    y = df_encoded['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_train_sc, y_train)\n",
    "\n",
    "    y_pred = log_reg.predict(X_test_sc)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, report\n",
    "print(accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e392ee-beb2-4428-9a02-95f09340878e",
   "metadata": {},
   "source": [
    "For question 4 there also seem to be no improvement when normalizing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1233e-adc9-4b29-98a2-18fc284a65b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
